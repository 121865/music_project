import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
from PIL import Image
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.impute import SimpleImputer
import seaborn as sns


# ==========================================
# music_phase4.py
# ä¸»è¦ç”¨é€”ï¼šè®€å– 'Spotify_Youtube.csv'ï¼Œåšè³‡æ–™å‰è™•ç†ã€è£œå€¼ã€åˆ†ç¾¤(PCA+KMeans)ã€
# èˆ‡å¤šå¼µè¦–è¦ºåŒ–åœ–è¡¨ç”¢ç”Ÿï¼ˆæ¯å¼µåœ–æœƒå„²å­˜åˆ° `information` ç›®éŒ„ï¼Œç¨‹å¼æœ€å¾ŒåŒæ™‚æ‰“é–‹æ‰€æœ‰åœ–çª—ï¼‰ã€‚
# é€™ä»½æª”æ¡ˆä»¥å‡½å¼åŒ–çµ„ç¹”ï¼Œé‡è¦çš„è™•ç†æ­¥é©Ÿçš†æœ‰å°æ‡‰çš„ plot_*() å‡½å¼ã€‚
# è¨»è§£ä»¥ä¸­æ–‡èªªæ˜ä¸»è¦è¡Œç‚ºèˆ‡å›å‚³å€¼ï¼Œæ–¹ä¾¿ç¶­è­·èˆ‡å¾ŒçºŒå»¶ä¼¸ã€‚
# ==========================================


def summarize_missing(df, title="ç¼ºå¤±å€¼çµ±è¨ˆ", max_rows=30):
    """
    åˆ—å°è³‡æ–™æ¡†çš„ç¼ºå¤±å€¼æ•¸é‡ï¼ˆé™åºï¼‰ã€‚

    åƒæ•¸:
    - df: pandas.DataFrame
    - title: å°è¡¨æ¨™é¡Œå­—ä¸²
    - max_rows: æœ€å¤šé¡¯ç¤ºå¤šå°‘å€‹æ¬„ä½ï¼ˆå…¶é¤˜ä»¥çœç•¥è¡¨ç¤ºï¼‰
    å›å‚³: Noneï¼ˆå°å‡ºçµæœä¾›äººå·¥æª¢è¦–ï¼‰
    """
    print(f"\nâ–¶ {title}")
    na = df.isna().sum()
    na = na[na > 0].sort_values(ascending=False)
    if na.empty:
        print("  âœ… ç„¡ç¼ºå¤±å€¼")
    else:
        print(na.head(max_rows).to_string())
        if len(na) > max_rows:
            print(f"  ... å¦æœ‰ {len(na) - max_rows} æ¬„çœç•¥")


def minmax(s: pd.Series) -> pd.Series:
    """
    ç°¡å–®çš„ min-max æ­£è¦åŒ–å‡½å¼ï¼Œå°‡åºåˆ—ç¸®æ”¾åˆ° 0â€“1 ç¯„åœã€‚
    è‹¥åºåˆ—å…¨ç‚ºå¸¸æ•¸æˆ–å…¨ç‚º NaNï¼Œå‰‡å›å‚³å€¼ç‚º 0 å‘é‡ä»¥é¿å…é™¤ä»¥é›¶ã€‚
    """
    s = pd.to_numeric(s, errors="coerce")
    mn, mx = s.min(skipna=True), s.max(skipna=True)
    if pd.isna(mn) or pd.isna(mx) or mn == mx:
        return pd.Series(np.zeros(len(s), dtype=float), index=s.index)
    return (s - mn) / (mx - mn)


def mood_category(v):
    """
    å°‡ Valenceï¼ˆ0â€“1ï¼‰åˆ†ç‚ºä¸‰å€‹æƒ…ç·’é¡åˆ¥ï¼šSad, Neutral, Happyã€‚
    å›å‚³å°æ‡‰çš„å­—ä¸²æ¨™ç±¤æˆ– NaNï¼ˆè‹¥è¼¸å…¥ç‚º NaNï¼‰ã€‚
    """
    if pd.isna(v):
        return np.nan
    elif v < 0.33:
        return 'Sad / Negative'
    elif v < 0.66:
        return 'Neutral / Moderate'
    else:
        return 'Happy / Positive'


def balanced_sample_per_mood(d: pd.DataFrame, mood_col: str, n: int, value_cols, seed: int = 42):
    """
    å° d ä¾ mood_col åˆ†çµ„ï¼Œæ¯çµ„æœ€å¤šå– n ç­†æ¨£æœ¬ã€‚
    value_cols å¯ç‚ºå­—ä¸²æˆ–å­—ä¸²åˆ—è¡¨ï¼›æœƒä¸€ä½µä¿ç•™ã€‚
    ä½¿ç”¨ã€Œéš¨æ©Ÿæ’åº + groupby().head(n)ã€ï¼Œé¿å… apply æ£„ç”¨è­¦å‘Šã€‚
    """
    # æ”¯æ´å‚³å…¥å–®ä¸€æ¬„ä½æˆ–å¤šæ¬„ä½çš„æƒ…æ³
    if isinstance(value_cols, str):
        keep_cols = [mood_col, value_cols]
    else:
        keep_cols = [mood_col] + list(value_cols)

    # ä½¿ç”¨ numpy çš„ RNG ç”¢ç”Ÿéš¨æ©Ÿæ’åºæ¬„ä½ï¼Œé¿å…ç›´æ¥ç”¨ sample() åœ¨åˆ†ç¾¤ä¸Šå°è‡´ä¸ç©©å®š
    rng = np.random.default_rng(seed)
    out = d[keep_cols].copy()
    out["__rand"] = rng.random(len(out))
    out = (
        out.sort_values("__rand")
           .groupby(mood_col, group_keys=False)
           .head(n)
           .drop(columns="__rand")
    )
    return out


def impute_likes_and_stream(df: pd.DataFrame) -> pd.DataFrame:
    """
    Likesï¼šä»¥ mean(likes/views) ä¼°è£œï¼ˆviews>0ï¼Œæœ‰é™å€¼ï¼‰
    Streamï¼šä»¥æ¯ä½ Artist çš„ median(stream/views) ä¼°è£œï¼›ç„¡å°æ‡‰è€…ç”¨å…¨åŸŸä¸­ä½æ•¸
    """
    # ç›®æ¨™ï¼šç›¡é‡åˆ©ç”¨ç¾æœ‰ Viewsã€Artist è³‡è¨Šï¼Œä¼°ç®—ç¼ºå¤±çš„ Likes / Stream
    # æ­¥é©Ÿï¼š1) å°‡æ¬„ä½è½‰æ•¸å€¼ 2) è¨ˆç®— like/view æ¯”ç‡ä¸¦è£œ Likes 3) è¨ˆç®— artist-level stream/views ä¸­ä½æ•¸ä¸¦è£œ Stream
    for c in ["Likes", "Views", "Stream", "Valence"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    if "Url_youtube" in df.columns:
        df["Url_youtube"] = df["Url_youtube"].astype("string")

    summarize_missing(df, "å‰ç½®è™•ç†å¾Œç¼ºå¤±å€¼")

    mask_ratio = df["Likes"].notna() & df["Views"].gt(0)
    tmp = df.loc[mask_ratio, ["Likes", "Views"]].copy()
    tmp["like_view_ratio"] = tmp["Likes"] / tmp["Views"]
    like_view_ratio = tmp.loc[np.isfinite(tmp["like_view_ratio"]), "like_view_ratio"].mean()

    print(f"\nä¼°è¨ˆçš„ like_view_ratio = {like_view_ratio:.6f}")
    cond_like = df["Likes"].isna() & df["Views"].gt(0)
    df.loc[cond_like, "Likes"] = df.loc[cond_like, "Views"] * like_view_ratio
    df["Likes"] = df["Likes"].round().astype("Int64")
    print(f"â†’ ä¾æ¯”ä¾‹è£œ Likes ç­†æ•¸ï¼š{int(cond_like.sum())}")

    g = df.loc[df["Stream"].notna() & df["Views"].gt(0), ["Artist", "Stream", "Views"]].copy()
    g["sv_ratio"] = g["Stream"] / g["Views"]
    sv = g.loc[np.isfinite(g["sv_ratio"]), ["Artist", "sv_ratio"]]
    artist_ratio = sv.groupby("Artist")["sv_ratio"].median()
    global_ratio = sv["sv_ratio"].median()
    print(f"å…¨åŸŸ Stream/Views ä¸­ä½æ¯”ä¾‹ = {global_ratio:.6f}")

    cond_stream = df["Stream"].isna() & df["Views"].gt(0)
    to_fill = df.loc[cond_stream, ["Artist", "Views"]].copy()
    to_fill["ratio"] = to_fill["Artist"].map(artist_ratio).fillna(global_ratio)
    df.loc[cond_stream, "Stream"] = (to_fill["Views"] * to_fill["ratio"]).round()
    df["Stream"] = pd.to_numeric(df["Stream"], errors="coerce").astype("Int64")
    print(f"â†’ ä¾è—äººæ¯”ä¾‹è£œ Stream ç­†æ•¸ï¼š{int(cond_stream.sum())}")

    summarize_missing(df, "è£œå€¼å¾Œç¼ºå¤±å€¼")
    return df


# å…¨åŸŸè¼¸å‡ºè¨­å®šï¼ˆä¾›å„ plot å‡½å¼å…±ç”¨ï¼‰
output_dir = r"C:\Users\cj6ru8cl6\Desktop\nschool\information"
os.makedirs(output_dir, exist_ok=True)
saved_images = []
_plot_counter = 0


def save_fig(name=None, dpi=150):
    """å„²å­˜ç›®å‰çš„ matplotlib åœ–è¡¨åˆ° output_dirï¼Œä¸¦é—œé–‰ç•¶å‰ figureã€‚
    name: æª”å (å¯åŒ…å«å‰¯æª”åæˆ–ä¸å«)ï¼Œæœƒè‡ªå‹•åŠ ä¸Šæ•¸å­—å‰ç¶´é¿å…è¦†å¯«ã€‚
    """
    global _plot_counter
    _plot_counter += 1
    if name is None:
        fname = f"{_plot_counter:02d}_plot.png"
    else:
        base = os.path.basename(name)
        fname = f"{_plot_counter:02d}_{base}"
    path = os.path.join(output_dir, fname)
    try:
        plt.tight_layout()
    except Exception:
        pass
    plt.savefig(path, dpi=dpi)
    saved_images.append(path)
    plt.close()
    return path

# ------------------------------------------
# ä»¥ä¸‹ç‚ºå¤šå€‹åœ–è¡¨ç”¢ç”Ÿå‡½å¼ï¼Œçš†æ¡ç”¨ save_fig() å„²å­˜æª”æ¡ˆï¼Œ
# ä¸¦ä»¥è³‡æ–™æ¡†æˆ–è¨ˆç®—å¾Œçš„æ•¸å€¼ä¾†ç¹ªåœ–ã€‚
# æ¯å€‹å‡½å¼å…§æœ‰è¼ƒè©³ç›¡çš„ç¨‹å¼æµç¨‹è¨»è§£ï¼Œä»¥åˆ©é–±è®€ã€‚
# ------------------------------------------


def plot_valence_trends(df: pd.DataFrame):
    """
    ç¹ªè£½ Valenceï¼ˆæƒ…ç·’ï¼‰èˆ‡å¹³å°äººæ°£çš„è¶¨å‹¢åœ–ï¼š
    - å…ˆè¨ˆç®— log1p äººæ°£ã€åˆ†ç®± valenceï¼Œä¸¦åšå¹³å°å…§ minmax æ­£è¦åŒ–
    - åˆ†åˆ¥ç‚º Spotify / YouTube ç•«å„è‡ªè¶¨å‹¢åœ–ï¼Œæœ€å¾Œç•«äº¤å‰å¹³å°æ¯”è¼ƒåœ–
    åœ–è¡¨æœƒä»¥ save_fig å„²å­˜ã€‚
    """
    for c in ["Valence", "Stream", "Views"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    df["log_Stream"] = np.log1p(df.get("Stream"))
    df["log_Views"] = np.log1p(df.get("Views"))
    bins = np.linspace(0, 1, 11)
    labels = [f"{b:.1f}-{b+0.1:.1f}" for b in bins[:-1]]
    df["valence_group"] = pd.cut(df["Valence"], bins=bins, labels=labels, include_lowest=True)
    df["norm_Stream"] = minmax(df["log_Stream"])
    df["norm_Views"] = minmax(df["log_Views"])

    spotify_v_trend = df.groupby("valence_group", observed=True)["norm_Stream"].mean().reset_index()
    youtube_v_trend = df.groupby("valence_group", observed=True)["norm_Views"].mean().reset_index()

    plt.figure(figsize=(8, 4))
    plt.plot(spotify_v_trend["valence_group"], spotify_v_trend["norm_Stream"], marker="o", linewidth=2)
    plt.title("Spotify Popularity vs Valence (Normalized)")
    plt.xlabel("Valence (0â€“1, binned)")
    plt.ylabel("Average Popularity (0â€“1, normalized)")
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    save_fig("01_spotify_valence_trend.png")

    plt.figure(figsize=(8, 4))
    plt.plot(youtube_v_trend["valence_group"], youtube_v_trend["norm_Views"], marker="o", linewidth=2)
    plt.title("YouTube Popularity vs Valence (Normalized)")
    plt.xlabel("Valence (0â€“1, binned)")
    plt.ylabel("Average Popularity (0â€“1, normalized)")
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    save_fig("02_youtube_valence_trend.png")

    plt.figure(figsize=(8, 4))
    plt.plot(spotify_v_trend["valence_group"], spotify_v_trend["norm_Stream"], marker="o", label="Spotify")
    plt.plot(youtube_v_trend["valence_group"], youtube_v_trend["norm_Views"], marker="s", label="YouTube")
    plt.title("Cross-Platform Popularity vs Valence (Normalized)")
    plt.xlabel("Valence (0â€“1, binned)")
    plt.ylabel("Average Popularity (0â€“1, normalized)")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)
    save_fig("03_crossplatform_valence_trend.png")


def plot_pop_by_mood(df: pd.DataFrame, target_n: int = 2500):
    """
    ä¾ Valence åˆ†é¡å‡ºçš„æƒ…ç·’ï¼ˆSad/Neutral/Happyï¼‰åšå¹³è¡¡æŠ½æ¨£å¾Œï¼Œ
    æ¯”è¼ƒ Spotify èˆ‡ YouTube çš„å¹³å‡äººæ°£ï¼ˆä»¥ log1p æ¸›å°‘æ¥µç«¯å€¼å½±éŸ¿ï¼‰ã€‚
    target_n æ±ºå®šæ¯å€‹æƒ…ç·’æ¯å¹³å°æœ€å¤šæŠ½æ¨£æ•¸ã€‚
    """
    df["Mood"] = df["Valence"].apply(mood_category)
    moods = ["Sad / Negative", "Neutral / Moderate", "Happy / Positive"]
    spotify_df = df.loc[df["log_Stream"].notna() & df["Mood"].notna(), ["Mood", "log_Stream"]].copy()
    youtube_df = df.loc[df["log_Views"].notna() & df["Mood"].notna(), ["Mood", "log_Views"]].copy()
    spotify_bal = balanced_sample_per_mood(spotify_df, "Mood", target_n, "log_Stream", seed=42)
    youtube_bal = balanced_sample_per_mood(youtube_df, "Mood", target_n, "log_Views", seed=42)
    print("\nSpotify æŠ½æ¨£åˆ†ä½ˆï¼š"); print(spotify_bal["Mood"].value_counts().to_string())
    print("\nYouTube æŠ½æ¨£åˆ†ä½ˆï¼š"); print(youtube_bal["Mood"].value_counts().to_string())
    spotify_bal_summary = spotify_bal.groupby("Mood")["log_Stream"].median().reindex(moods)
    youtube_bal_summary = youtube_bal.groupby("Mood")["log_Views"].median().reindex(moods)

    x = np.arange(len(moods)); width = 0.35
    plt.figure(figsize=(7, 4))
    plt.bar(x - width / 2, spotify_bal_summary.values, width, label="Spotify (balanced)")
    plt.bar(x + width / 2, youtube_bal_summary.values, width, label="YouTube (balanced)")
    plt.xticks(x, moods)
    plt.ylabel("Average Popularity (log scale)")
    plt.title(f"Cross-Platform Popularity by Mood (Balanced Sampling, n={target_n}/mood-platform)")
    plt.legend()
    plt.grid(axis="y", alpha=0.3)
    save_fig("04_pop_by_mood.png")


def plot_clustering_overview(df: pd.DataFrame):
    """
    æ•´é«”åˆ†ç¾¤æµç¨‹ï¼š
    - é¸å®šéŸ³è¨Šç‰¹å¾µï¼Œåšä¸­ä½æ•¸è£œå€¼èˆ‡ Z-score æ¨™æº–åŒ–
    - è¨ˆç®— Elbow åœ–æª¢è¦– k çš„é¸æ“‡
    - ä½¿ç”¨ KMeans åˆ†ç¾¤ï¼Œä¸¦ä»¥ PCA(2) æŠ•å½±åšæ•£ä½ˆè¦–è¦ºåŒ–
    - åˆ—å°æ¯ç¾¤å¹³å‡éŸ³æ¨‚ç‰¹å¾µèˆ‡å¹³å‡äººæ°£
    """
    features = [
        "Danceability", "Energy", "Speechiness", "Acousticness",
        "Instrumentalness", "Liveness", "Valence", "Tempo"
    ]
    for c in features:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    df_cluster = df[features + ["Artist", "Track", "Stream", "Views"]].dropna().copy()
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df_cluster[features])

    inertia = []
    K_range = range(2, 9)
    for k in K_range:
        km = KMeans(n_clusters=k, random_state=42, n_init="auto")
        km.fit(X_scaled)
        inertia.append(km.inertia_)

    plt.figure(figsize=(5, 3))
    plt.plot(list(K_range), inertia, marker="o")
    plt.title("Elbow Method for Optimal K")
    plt.xlabel("Number of Clusters (k)"); plt.ylabel("Inertia")
    plt.grid(True)
    save_fig("05_elbow_k.png")

    k = 4
    kmeans = KMeans(n_clusters=k, random_state=42, n_init="auto")
    df_cluster["cluster"] = kmeans.fit_predict(X_scaled)
    pca = PCA(n_components=2)
    p2 = pca.fit_transform(X_scaled)
    df_cluster["pca1"] = p2[:, 0]; df_cluster["pca2"] = p2[:, 1]

    # åˆ—å° PCA è¨ºæ–·è³‡è¨Šï¼šè§£é‡‹è®Šç•°æ¯”ä¾‹èˆ‡å„ç‰¹å¾µ loadingï¼ˆæ–¹ä¾¿è§£é‡‹ PC1 / PC2ï¼‰
    try:
        print("\nPCA explained variance ratio (overall):", pca.explained_variance_ratio_)
        print("PCA loadings (components):")
        for i, comp in enumerate(pca.components_, start=1):
            print(f" PC{i}:")
            for fname, val in zip(features, comp):
                print(f"   {fname}: {val:.4f}")
    except Exception:
        pass

    plt.figure(figsize=(7, 5))
    for cid in sorted(df_cluster["cluster"].unique()):
        sub = df_cluster[df_cluster["cluster"] == cid]
        plt.scatter(sub["pca1"], sub["pca2"], s=12, alpha=0.6, label=f"cluster {cid}")
    plt.title("Song Clusters (PCA Projection)")
    plt.xlabel("PCA-1"); plt.ylabel("PCA-2")
    plt.legend(markerscale=2); plt.grid(True, alpha=0.3)
    save_fig("06_clusters_pca.png")

    cluster_features = df_cluster.groupby("cluster")[features].mean().round(3)
    print("\nå„ç¾¤å¹³å‡éŸ³æ¨‚ç‰¹å¾µï¼š")
    print(cluster_features.to_string())
    cluster_pop = (df_cluster.groupby("cluster")[['Stream', 'Views']].mean().pipe(np.log1p).round(3))
    print("\nå„ç¾¤å¹³å‡äººæ°£ (log scale)ï¼š")
    print(cluster_pop.to_string())

    plt.figure(figsize=(7, 4))
    x = np.arange(k); width = 0.35
    plt.bar(x - width / 2, cluster_pop['Stream'].values, width, label="Spotify (Stream)")
    plt.bar(x + width / 2, cluster_pop['Views'].values, width, label="YouTube (Views)")
    plt.xticks(x, [f"C{cid}" for cid in range(k)])
    plt.ylabel("Average Popularity (log scale)")
    plt.title("Average Popularity by Cluster (log scale)")
    plt.legend(); plt.grid(axis="y", alpha=0.3)
    save_fig("07_avg_pop_by_cluster.png")


def plot_platform_specific_clusterings(df: pd.DataFrame):
    """
    å° Spotify èˆ‡ YouTube åˆ†åˆ¥åšåˆ†ç¾¤åˆ†æï¼ˆä»¥è©²å¹³å°æœ‰å€¼çš„æ¨£æœ¬ç‚ºåŸºç¤ï¼‰ï¼š
    - ä»¥ä¸­ä½æ•¸è£œç¼º + StandardScaler
    - å„å¹³å°åˆ†ç¾¤å¾Œè¨ˆç®—ç¾¤å…§å¹³å‡ç‰¹å¾µä¸¦ç•«ç†±åœ–
    - äº¦åš PCA æŠ•å½±ä¸¦ç•«åˆ†ç¾¤æ•£ä½ˆ
    """
    features = [
        "Danceability", "Energy", "Speechiness", "Acousticness",
        "Instrumentalness", "Liveness", "Valence", "Tempo"
    ]
    for c in features:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    spotify_cluster = df[features + ["Stream"]].copy()
    spotify_cluster = spotify_cluster[spotify_cluster["Stream"].notna()]
    imp_sp = SimpleImputer(strategy="median")
    X_sp_filled = imp_sp.fit_transform(spotify_cluster[features])
    scaler_sp = StandardScaler()
    X_sp = scaler_sp.fit_transform(X_sp_filled)

    youtube_cluster = df[features + ["Views"]].copy()
    youtube_cluster = youtube_cluster[youtube_cluster["Views"].notna()]
    imp_yt = SimpleImputer(strategy="median")
    X_yt_filled = imp_yt.fit_transform(youtube_cluster[features])
    scaler_yt = StandardScaler()
    X_yt = scaler_yt.fit_transform(X_yt_filled)

    k = 4
    kmeans_sp = KMeans(n_clusters=k, random_state=42, n_init=10)
    spotify_cluster["cluster_sp"] = kmeans_sp.fit_predict(X_sp)
    kmeans_yt = KMeans(n_clusters=k, random_state=42, n_init=10)
    youtube_cluster["cluster_yt"] = kmeans_yt.fit_predict(X_yt)

    sp_features = (
        pd.DataFrame(X_sp_filled, columns=features, index=spotify_cluster.index)
          .assign(cluster_sp=spotify_cluster["cluster_sp"])
          .groupby("cluster_sp")[features].mean().round(3)
    )
    yt_features = (
        pd.DataFrame(X_yt_filled, columns=features, index=youtube_cluster.index)
          .assign(cluster_yt=youtube_cluster["cluster_yt"])
          .groupby("cluster_yt")[features].mean().round(3)
    )
    print("\nğŸ§ Spotify å„ç¾¤å¹³å‡ç‰¹å¾µï¼š")
    print(sp_features.to_string())
    print("\nğŸ“º YouTube å„ç¾¤å¹³å‡ç‰¹å¾µï¼š")
    print(yt_features.to_string())
    sp_pop = spotify_cluster.groupby("cluster_sp")["Stream"].mean().pipe(np.log1p).round(3)
    yt_pop = youtube_cluster.groupby("cluster_yt")["Views"].mean().pipe(np.log1p).round(3)
    print("\nğŸ§ Spotify å„ç¾¤å¹³å‡äººæ°£ (log1p Stream)ï¼š")
    print(sp_pop.to_string())
    print("\nğŸ“º YouTube å„ç¾¤å¹³å‡äººæ°£ (log1p Views)ï¼š")
    print(yt_pop.to_string())

    plt.figure(figsize=(10, 4))
    plt.subplot(1, 2, 1)
    sns.heatmap(sp_features, cmap="YlGnBu", annot=True, fmt=".2f")
    plt.title("Spotify Cluster Feature Means")

    plt.subplot(1, 2, 2)
    sns.heatmap(yt_features, cmap="YlOrRd", annot=True, fmt=".2f")
    plt.title("YouTube Cluster Feature Means")
    save_fig("08_cluster_feature_heatmaps.png")

    pca_sp = PCA(n_components=2, random_state=42)
    pca_yt = PCA(n_components=2, random_state=42)
    sp_p2 = pca_sp.fit_transform(X_sp)
    yt_p2 = pca_yt.fit_transform(X_yt)
    spotify_cluster["pca1"], spotify_cluster["pca2"] = sp_p2[:, 0], sp_p2[:, 1]
    youtube_cluster["pca1"], youtube_cluster["pca2"] = yt_p2[:, 0], yt_p2[:, 1]
    # åˆ—å°å¹³å°åˆ¥ PCA è¨ºæ–·è³‡è¨Š
    try:
        print("\nSpotify PCA explained variance ratio:", pca_sp.explained_variance_ratio_)
        print("Spotify PCA loadings:")
        for i, comp in enumerate(pca_sp.components_, start=1):
            print(f" PC{i}:")
            for fname, val in zip(features, comp):
                print(f"   {fname}: {val:.4f}")
    except Exception:
        pass
    try:
        print("\nYouTube PCA explained variance ratio:", pca_yt.explained_variance_ratio_)
        print("YouTube PCA loadings:")
        for i, comp in enumerate(pca_yt.components_, start=1):
            print(f" PC{i}:")
            for fname, val in zip(features, comp):
                print(f"   {fname}: {val:.4f}")
    except Exception:
        pass
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    sns.scatterplot(data=spotify_cluster, x="pca1", y="pca2",
                    hue="cluster_sp", palette="Set2", s=15, alpha=0.6)
    plt.title("Spotify Clusters (PCA Projection)")
    plt.legend(title="Cluster", markerscale=2)

    plt.subplot(1, 2, 2)
    sns.scatterplot(data=youtube_cluster, x="pca1", y="pca2",
                    hue="cluster_yt", palette="Set1", s=15, alpha=0.6)
    plt.title("YouTube Clusters (PCA Projection)")
    plt.legend(title="Cluster", markerscale=2)
    save_fig("09_pca_platforms.png")


def plot_feature_correlations(df: pd.DataFrame):
    """
    è¨ˆç®—ç‰¹å¾µï¼ˆfeaturesï¼‰èˆ‡äººæ°£ï¼ˆStream / Viewsï¼‰ä¹‹é–“çš„ Pearson ç›¸é—œä¿‚æ•¸ï¼Œ
    ä¸¦ç”Ÿæˆé•·æ¢åœ–èˆ‡ç†±åœ–ä»¥è¦–è¦ºåŒ–æ¯”è¼ƒã€‚
    """
    features = ["Danceability", "Energy", "Valence", "Tempo",
                 "Acousticness", "Instrumentalness", "Speechiness"]
    spotify_corr = df[features + ["Stream"]].corr()["Stream"].drop("Stream")
    youtube_corr = df[features + ["Views"]].corr()["Views"].drop("Views")
    corr_compare = pd.DataFrame({
        "Spotify (Stream Corr)": spotify_corr,
        "YouTube (Views Corr)": youtube_corr
    }).round(3)
    print("ğŸ¯ éŸ³æ¨‚ç‰¹å¾µèˆ‡äººæ°£çš„ç›¸é—œæ€§æ¯”è¼ƒï¼š")
    print(corr_compare)
    corr_compare.plot(kind="bar", figsize=(8, 4))
    plt.title("Featureâ€“Popularity Correlation by Platform")
    plt.ylabel("Correlation (Pearson r)")
    plt.grid(axis="y", alpha=0.3)
    save_fig("10_feature_pop_corr.png")
    yt_corr = df[["Likes", "Comments"] + features].corr()
    sns.heatmap(yt_corr.loc[["Likes", "Comments"], features], annot=True, cmap="coolwarm")
    plt.title("YouTube Interaction vs Audio Features")
    save_fig("11_yt_interaction_vs_features.png")


def show_saved_images_nonblocking():
    # æ¯å¼µåœ–å„è‡ªé–‹è¦–çª—ä¸¦åŒæ™‚é¡¯ç¤ºï¼ˆéåŒ¯é›†æˆä¸€å¼µåœ–ï¼‰
    if saved_images:
        plt.ion()
        figs = []
        for img_path in saved_images:
            try:
                img = Image.open(img_path)
                fig = plt.figure(figsize=(6, 4))
                ax = fig.add_subplot(111)
                ax.imshow(img)
                ax.axis('off')
                ax.set_title(os.path.basename(img_path))
                figs.append(fig)
            except Exception:
                fig = plt.figure(figsize=(4, 3))
                fig.text(0.5, 0.5, 'Failed to load', ha='center')
                figs.append(fig)
        plt.show(block=False)
        try:
            input("æ‰€æœ‰åœ–è¡¨å·²é–‹åœ¨ç¨ç«‹è¦–çª—ã€‚æŒ‰ Enter éµä»¥é—œé–‰æ‰€æœ‰è¦–çª—ä¸¦çµæŸç¨‹å¼...\n")
        except Exception:
            pass
        plt.close('all')


# main() ç‚ºç¨‹å¼ä¸»å…¥å£ï¼Œè² è²¬è®€å– CSVã€å‘¼å«å„è™•ç†/ç¹ªåœ–å‡½å¼ï¼Œæœ€å¾Œé¡¯ç¤ºå·²å„²å­˜çš„åœ–æª”
def main(csv_path: str = r"C:\Users\cj6ru8cl6\Desktop\nschool\Spotify_Youtube.csv"):
    df = pd.read_csv(csv_path)
    df = impute_likes_and_stream(df)
    plot_valence_trends(df)
    plot_pop_by_mood(df)
    plot_clustering_overview(df)
    plot_platform_specific_clusterings(df)
    plot_feature_correlations(df)
    show_saved_images_nonblocking()


if __name__ == "__main__":
    # ç¢ºä¿ output ç›®éŒ„å­˜åœ¨ï¼ˆsave_fig ä¾è³´ï¼‰
    os.makedirs(output_dir, exist_ok=True)
    main()

